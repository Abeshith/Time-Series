# -*- coding: utf-8 -*-
"""Time Series Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Lnjwt47XOMEoZr5pl-N8soUIRhorL4P
"""

import numpy as np
import pandas as pd
import plotly.graph_objs as go
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping
import joblib
import yfinance as yf
from datetime import datetime

ticker = 'NVDA'
start_date = '2020-01-01'
end_date = datetime.now().strftime('%Y-%m-%d')

data = yf.download(ticker, start=start_date, end=end_date)

# Show all features
data.head()

fig = go.Figure()
fig.add_trace(go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price'))
fig.update_layout(title=f'{ticker} Closing Price', xaxis_title='Date', yaxis_title='Price')
fig.show()

n_steps = 10
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))

X, y = [], []
for i in range(len(scaled_data) - n_steps):
    X.append(scaled_data[i:i+n_steps])
    y.append(scaled_data[i+n_steps])
X, y = np.array(X), np.array(y)

split = int(len(X) * 0.8)
X_train, y_train = X[:split], y[:split]
X_test, y_test = X[split:], y[split:]

# Build and train LSTM model
model = Sequential()
model.add(LSTM(100, activation='relu', input_shape=(n_steps, 1), return_sequences=True))
model.add(LSTM(50, activation='relu'))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit(X_train, y_train, epochs=50, validation_split=0.2, verbose=0, callbacks=[early_stopping])

# Plot training history
fig = go.Figure()
fig.add_trace(go.Scatter(x=np.arange(len(history.history['loss'])), y=history.history['loss'], mode='lines', name='Training Loss'))
fig.add_trace(go.Scatter(x=np.arange(len(history.history['val_loss'])), y=history.history['val_loss'], mode='lines', name='Validation Loss'))
fig.update_layout(title='Model Loss Over Epochs', xaxis_title='Epochs', yaxis_title='Loss')
fig.show()

fig = go.Figure()
fig.add_trace(go.Scatter(x=np.arange(len(history.history['mae'])), y=history.history['mae'], mode='lines', name='Training MAE'))
fig.add_trace(go.Scatter(x=np.arange(len(history.history['val_mae'])), y=history.history['val_mae'], mode='lines', name='Validation MAE'))
fig.update_layout(title='Model MAE Over Epochs', xaxis_title='Epochs', yaxis_title='Mean Absolute Error (MAE)')
fig.show()

forecast_periods = 2
forecast = []
last_sequence = X[-1]
for _ in range(forecast_periods):
    pred = model.predict(last_sequence.reshape((1, n_steps, 1)))
    forecast.append(pred[0, 0])
    last_sequence = np.append(last_sequence[1:], pred[0, 0])
forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1))

# Plot actual vs predicted
fig = go.Figure()

# Plot actual values
fig.add_trace(go.Scatter(
    x=data.index[-len(y_test):],
    y=scaler.inverse_transform(y_test).flatten(),
    mode='lines',
    name='Actual'
))

# Plot predicted values
forecast_dates = pd.date_range(start=data.index[-1] + pd.Timedelta(days=1), periods=forecast_periods, freq='B')
fig.add_trace(go.Scatter(
    x=forecast_dates,
    y=forecast.flatten(),
    mode='markers+lines',  # Scatter and lines
    name='Predicted'
))

fig.update_layout(
    title='Actual vs Predicted Prices',
    xaxis_title='Date',
    yaxis_title='Price'
)

fig.show()

joblib.dump(model, 'lstm_model.pkl')